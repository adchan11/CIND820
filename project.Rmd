---
title: "CIND 820 - Initial Results and Analysis"
output: html_document
---

```{r setup, include=FALSE}
################################################
#DATA CLEANING
################################################

#Load libraries
library(dplyr)
library(tidyr)

#Load data

df_raw <- read.table("https://leicester.figshare.com/ndownloader/files/23581310", sep = ",", header = TRUE, stringsAsFactors = FALSE)

#Create new class variable

df_comp <- df_raw[113:124]

df_comp$LET_IS_binary <- ifelse(df_comp$LET_IS == 0, 0, 1)

df_comp <- df_comp %>%
  select(-LET_IS)

df_comp$any_complication <- rowSums(df_comp)

df_comp$any_complication <- ifelse(df_comp$any_complication == 0, 0, 1)

df_raw$any_complication <- df_comp$any_complication

#Select only relevant features based on scope of research questions
medical_history_var <- c(4:8, 11:12, 13:34)
symptoms_var <-c(9:10, 35:43, 49, 83:91)
drugs_var <- c(75:82, 96:112)

df <- df_raw %>% 
  dplyr:::select(c(2:3, all_of(medical_history_var), all_of(symptoms_var), all_of(drugs_var), "any_complication"))
```

``````{r setup, include=FALSE}
#Transform Blood Pressure Variables

#Filter if any of the blood pressure variables equal 0
df_blood_invalid <- df %>% 
  filter(if_any(c(S_AD_KBRIG, D_AD_KBRIG, S_AD_ORIT, D_AD_ORIT), ~ . == 0)) 
head(df_blood_invalid, 10)

#Remove rows where any of the blood pressure variables equal 0

df <- df %>% 
  mutate(has_zero = if_any(c(S_AD_KBRIG, D_AD_KBRIG, S_AD_ORIT, D_AD_ORIT), ~ . == 0)) %>%
  mutate(has_zero = ifelse(is.na(has_zero), FALSE, has_zero)) %>%
  filter(has_zero == FALSE) %>%
  select(-has_zero)

#Transform new systolic and diastolic variables 

df$Systolic <- ifelse(is.na(df$S_AD_KBRIG) | is.na(df$S_AD_ORIT), coalesce(df$S_AD_KBRIG, df$S_AD_ORIT), 
                      (df$S_AD_KBRIG + df$S_AD_ORIT) / 2)

length(which(is.na(df$Systolic)))

df$Diastolic <- ifelse(is.na(df$D_AD_KBRIG) | is.na(df$D_AD_ORIT), coalesce(df$D_AD_KBRIG, df$D_AD_ORIT), 
                      (df$D_AD_KBRIG + df$D_AD_ORIT) / 2)

length(which(is.na(df$Diastolic)))

#Remove pre-existing blood pressure variables and just keep Systolic blood pressure

df <- df %>%
  select(-c('S_AD_KBRIG', 'S_AD_ORIT', 'D_AD_KBRIG', 'D_AD_ORIT', 'Diastolic')) %>%
  relocate(Systolic, .before = K_BLOOD)
```



```{r setup, include=FALSE}
#Create histograms 

misfun <- function(z) {paste(
  paste(c('n', 'm'), table(factor(as.double(is.na(z)), levels=0:1)), sep=':'), 
  collapse=' ')}

num1 <- 1
num2 <- 20
for (i in 1:(ceiling(length(df)/20))) {

if (i == 4) {
  num2 <- 75
}
png(paste0('hist', i, '.png'), 1000, 1000)
par(mfrow=c(5,4))

df_new <- df[num1:num2]
lapply(names(df_new), function(x) hist(df_new[[x]], main=x, xlab=misfun(df_new[x]),  cex.lab=1.5, cex.axis=1.5, cex.main = 1.5, cex.sub=1.5,
                                   breaks = 'FD'))
dev.off()
num1 <- num2 + 1
num2 <- 20 * (1 + i)
}

#Drop variables with too much missing data

df <- df %>%
  select(-c("KFK_BLOOD", "IBS_NASL"))
```

```{r fig.align="center", echo = FALSE,fig.height = 10, fig.width = 10}
#Box plots using t-test
library(rstatix)
library(ggpubr)

#Do not include KFK_BLOOD (variable 89) as it only has 4 records and the rest are missing values
numeric_cols = c("AGE", "Systolic", "K_BLOOD", "NA_BLOOD", "ALT_BLOOD", "AST_BLOOD", "L_BLOOD", "ROE")

df_numeric <- df %>% 
  select(any_of(c(numeric_cols, "any_complication")))

df_long <- df_numeric %>%
  pivot_longer(-`any_complication`, names_to = "variables", values_to = "value") %>%
  as.data.frame()

#Remove NA values
df_long <- df_long[!is.na(df_long$value),]

#Generate boxplots and include t-test significance results
df_stats <- df_long %>%
  group_by(variables) %>%
  t_test(value ~ any_complication) %>%
  # adjust_pvalue(method = "BH") %>%
  add_significance()

df_boxplots <- ggboxplot(
  df_long, x = "any_complication", y = "value",
  fill = "any_complication", palette = "npg", legend = "none", order = NULL,
  ggtheme = theme_pubr(border = TRUE)
  ) +
  facet_wrap(~variables ,scales = "free_y") 

df_stats <- df_stats %>% 
  add_xy_position(x = "any_complication", scales = 'free', step.increase = 1) 


df_boxplots +stat_pvalue_manual(df_stats, label = "p.signif") + 
 font("title", size = 14,  face = "bold")+
 font("xy.text", size = 12, face = "bold")

#Remove non significant variables

df <- df %>%
  select(-c('ALT_BLOOD', 'AST_BLOOD'))
```

```{r setup, include=FALSE}
#Correlation plot for numeric variables
#Point-Biserial coefficient with t-test for significance
library(corrplot)

#Select only numeric variables
df_corr_numeric <- df_numeric 

#Generate significance values at confidence level = 0.95
testRes <- cor.mtest(df_corr_numeric, conf.level = 0.95) 

#Generate correlation plot with statistical significance
corrplot(cor(df_corr_numeric, use = 'pairwise.complete.obs'), p.mat = testRes$p, method = "color", diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, 
         insig = 'label_sig', pch.col = 'purple')


# Reference: http://web.pdx.edu/~newsomj/pa551/lectur15.htm
```

```{r fig.align="center", echo = FALSE,fig.height = 10, fig.width = 10}
#Correlation plot for binary variables
#Phi Coefficient correlation
library(corrplot)

#Select binary attributes only
binary_cols <- c(3, 8, 10, 13:34, 39:44, 49:74, 76:83, 85, 96:99, 106:112)
df_corr_binary_raw <- df_raw[binary_cols]
df_corr_binary <- df %>% 
  select(any_of(c(colnames(df_corr_binary_raw), "any_complication")))

#Split into two datasets so that the correlation plot is easier to read 

df_corr_binary_1 <- df_corr_binary[c(1:24, 51)]
df_corr_binary_2 <- df_corr_binary[25:51]

#Function to generate a matrix of chi-square test values
chisqmatrix <- function(x) {
  names <- colnames(x);  num = length(names)
  m <- matrix(nrow=num,ncol=num,dimnames=list(names,names))
  for (i in 1:(num-1)) {
    for (j in (i+1):num) {
      m[i,j] <- tryCatch(
        {chisq.test(x[,i],x[,j],simulate.p.value = TRUE)$p.value
        },
        error=function(x){
          return(NA)
        }
      )
    }
  }
  return (m)
}

#Generate significance values
testRes_1 <- chisqmatrix(df_corr_binary_1)
testRes_2 <- chisqmatrix(df_corr_binary_2)

#Generate correlation plot with statistical significance
corrplot(cor(df_corr_binary_1, use = "pairwise.complete.obs"), p.mat = testRes_1, method = "color", diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.8, 
         insig = 'label_sig', pch.col = 'purple', na.label = "NA", number.cex = 0.5, tl.cex = 0.8)

corrplot(cor(df_corr_binary_2, use = "pairwise.complete.obs"), p.mat = testRes_2, method = "color", diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.8, 
         insig = 'label_sig', pch.col = 'purple', na.label = "NA", number.cex = 0.5, tl.cex = 0.8)

# References:
# https://stat.ethz.ch/pipermail/r-help/2015-April/428127.html
# http://web.pdx.edu/~newsomj/pa551/lectur15.htm
# http://www.ce.memphis.edu/7012/L17_CategoricalVariableAssociation.pdf
```

```{r fig.align="center", echo = FALSE,fig.height = 10, fig.width = 10}
#Correlation plot for categorical/ordinal variables
#CramÃ©r's V
library(corrplot)

#Select ordinal variables only
ordinal_cols <- c(4, 5, 6, 7, 9, 11, 12, 45:48, 92:95, 100:105)

df_corr_ordinal_raw <- df_raw[ordinal_cols]
df_corr_ordinal <- df %>% 
  select(any_of(c(colnames(df_corr_ordinal_raw), "any_complication")))

#Create matrix of chi-square test values
mat <- chisqmatrix(df_corr_ordinal)

#Generate correlation plot with chi-square test significance 
corrplot::corrplot(DescTools::PairApply(df_corr_ordinal, DescTools::CramerV), p.mat = mat, method = 'color', diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, 
         insig = 'label_sig', pch.col = 'purple', na.label = "NA", number.cex = 0.5, tl.cex = 0.8)

# Reference:
# https://stackoverflow.com/questions/32732582/chi-square-p-value-matrix-in-r
```

```{r setup, include=FALSE}
#Train/test split
for(i in 1:ncol(df)) {                                   # Replace NA in all columns
  df[ , i][is.na(df[ , i])] <- median(df[ , i], na.rm = TRUE)
}

index <- sort(sample(nrow(df), nrow(df)*.7))
train <- df[index,]
test <- df[-index,]

medical_history_cols <- c(4:8, 11:12, 13:34)
symptoms_cols <- c(9:10, 35:43, 49, 83:91)
drugs_cols <- c(76:82, 96:112)
missing_values_cols <- c('KFK_BLOOD', 'S_AD_KBRIG', 'D_AD_KBRIG', 'IBS_NASL')
new_train <- train[c(medical_history_cols, symptoms_cols, drugs_cols, 125)] %>%
  select(-all_of(missing_values_cols))

new_test <- test %>% 
  select(all_of(colnames(new_train)))
  
lapply(new_train, function(x) length(which(is.na(x))))
```

```{r setup, include=FALSE}
#Logistic Regression

sig_cols <- c('LID_S_n', 'NITR_S', 'NOT_NA_KB', 'NA_BLOOD', 'O_L_POST', 'zab_leg_02', 'zab_leg_01', 'endocr_01')
train_final <- new_train %>% select(all_of(c(sig_cols, 'any_complication')))
test_final <- new_test %>% select(all_of(c(sig_cols, 'any_complication')))

LR_model <- glm(any_complication ~.,family = binomial(link = 'logit'), data = train, na.action = na.omit)
summary(LR_model)
# https://datascienceplus.com/perform-logistic-regression-in-r/#:~:text=Logistic%20regression%20is%20a%20method,general%2C%20can%20assume%20different%

#https://www.datacamp.com/community/tutorials/logistic-regression-R
#https://towardsdatascience.com/machine-learning-with-r-logistic-regression-152ec20351db
result <- predict(LR_model, newdata = test, type = 'response')

# optCutOff <- optimalCutoff(test$Churn, result)[1] 
preds<- ifelse(result > 0.5, 1,0 )

## Confusion matrix and statistics
library(caret)
caret::confusionMatrix(factor(preds), factor(test$any_complication), mode = "everything", positive = "1")

# https://stackoverflow.com/questions/70905642/error-in-lm-fitx-y-na-nan-inf-in-x-in-r

```

```{r setup, include=FALSE}
#Naive Bayes
library('e1071')
 m <- naiveBayes(as.factor(any_complication) ~ ., data = train)
 m$tables
 print(m)


 y_pred <- predict(m, test)
#
 table(y_pred, test$any_complication)
#
 cm <- table(y_pred, new_test$any_complication)
 cm

```

```{r setup, include=FALSE}
#Random Forest
library(randomForest)

train_RF <- train
train_RF$any_complication <- as.character(train_RF$any_complication)
train_RF$any_complication <- as.factor(train_RF$any_complication)

RF_model <- randomForest(any_complication ~., data=train_RF, proximity = TRUE, na.action = na.exclude) 

preds <- predict(RF_model, test)

caret::confusionMatrix(factor(preds), factor(test$any_complication), mode = "everything", positive = "1")

# https://www.r-bloggers.com/2021/04/random-forest-in-r/
# https://discuss.analyticsvidhya.com/t/what-does-the-warning-the-response-has-five-or-fewer-unique-values-while-building-random-forest-mean/6442/2
```

```{r setup, include=FALSE}
#Neural Network
library(neuralnet)

#Fill in missing values with median to allow NN to train
train_NN <- train

for(i in 1:ncol(train_NN)) {                                   # Replace NA in all columns
  train_NN[ , i][is.na(train_NN[ , i])] <- median(train_NN[ , i], na.rm = TRUE)
}

NN_model <- neuralnet(any_complication ~ ., data = train_NN, hidden = c(2,1), linear.output = FALSE, threshold=0.01)


#Test the resulting output
test_NN <- test %>% 
  select(-any_complication)

nn.results <- compute(NN_model, test_NN)
results <- data.frame(actual = test$any_complication, prediction = nn.results$net.result)

roundedresults<-sapply(results,round,digits=0)
roundedresultsdf=data.frame(roundedresults)
attach(roundedresultsdf)
confusionMatrix(table(actual,prediction), positive = "1", mode = 'everything')
# https://stackoverflow.com/questions/63770095/how-to-print-confusion-matrix-of-neuralnet-predicted-probabilities
# https://datascienceplus.com/neuralnet-train-and-test-neural-networks-using-r/

library(nnet)

irispred <- nnet(any_complication ~ ., data = train_NN, size=10)
result <- predict(irispred, newdata = test_final)
preds <- ifelse(result > 0.5, 1,0 )

confusionMatrix(data = factor(preds), reference = factor(test_final$any_complication), mode = "everything", positive = "1")

result <- predict(LR_model, newdata = new_test, type = 'response')

# optCutOff <- optimalCutoff(test$Churn, result)[1] 
preds<- ifelse(result > 0.5, 1,0 )


```