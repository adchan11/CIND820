---
title: "project"
output: html_document
---

```{r setup, include=FALSE}
#Load libraries
library(dplyr)

#Load data

df <- read.table("https://leicester.figshare.com/ndownloader/files/23581310", sep = ",", header = TRUE, stringsAsFactors = FALSE)

#Create new class variable

df_comp <- df[113:124]

df_comp$LET_IS_binary <- ifelse(df_comp$LET_IS == 0, 0, 1)

df_comp <- df_comp %>%
  select(-LET_IS)

df_comp$any_complication <- rowSums(df_comp)

df_comp$any_complication <- ifelse(df_comp$any_complication == 0, 0, 1)

df$any_complication <- df_comp$any_complication

```

```{r setup, include=FALSE}
#Create histograms 

misfun <- function(z) {paste(
  paste(c('n', 'm'), table(factor(as.double(is.na(z)), levels=0:1)), sep=':'), 
  collapse=' ')}

num1 <- 1
num2 <- 20
for (i in 1:(ceiling(length(df)/20))) {

if (i == 7) {
  num2 <- 125
}
png(paste0('hist', i, '.png'), 1000, 1000)
par(mfrow=c(5,4))

df_new <- df[num1:num2]
lapply(names(df_new), function(x) hist(df_new[[x]], main=x, xlab=misfun(df_new[x]),  cex.lab=1.5, cex.axis=1.5, cex.main = 1.5, cex.sub=1.5,
                                   breaks = 'FD'))
dev.off()
num1 <- num2 + 1
num2 <- 20 * (1 + i)
}
```

```{r fig.align="center", echo = FALSE,fig.height = 15, fig.width = 10}
#Box plots using t-test
library(rstatix)
library(ggpubr)

#Do not include KFK_BLOOD (variable 89) as it only has 4 records and the rest are missing values
numeric_cols = c(2, 35, 36, 37, 38, 84, 86, 87, 88, 90, 91)

df_numeric <- df[c(numeric_cols, which(colnames(df) == "any_complication"))]

df_long <- df_numeric %>%
  pivot_longer(-`any_complication`, names_to = "variables", values_to = "value") %>%
  as.data.frame()

#Remove NA values
df_long <- df_long[!is.na(df_long$value),]

df_stats <- df_long %>%
  group_by(variables) %>%
  t_test(value ~ any_complication) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance()

df_boxplots <- ggboxplot(
  df_long, x = "any_complication", y = "value",
  fill = "any_complication", palette = "npg", legend = "none", order = NULL,
  ggtheme = theme_pubr(border = TRUE)
  ) +
  facet_wrap(~variables ,scales = "free_y") 

df_stats <- df_stats %>% 
  add_xy_position(x = "any_complication", scales = 'free', step.increase = 1) 


df_boxplots +stat_pvalue_manual(df_stats, label = "p.adj.signif") + 
 font("title", size = 14,  face = "bold")+
 

 # font("xlab", size = 12, color = "blue")+
 # font("ylab", size = 12, color = "#993333")+
 font("xy.text", size = 12, face = "bold") 

# graphs <- df_long %>%
#   group_by(variables) %>%
#   doo(
#     ~ggboxplot(
#       data =., x = "any_complication", y = "value",
#       fill = "any_complication", palette = "npg", legend = "none",xlab = FALSE, ylab = FALSE,
#       ggtheme = theme_pubr(border = TRUE)
#       ),
#     result = "plots"
#   )
# graphs
# 
# 
# variables <- graphs$variables
# for(i in 1:length(variables)){
#    assign(paste("graph.", i, sep = ""), graphs$plots[[i]] +
#     labs(title = variables[i]) +
#     stat_pvalue_manual(df_stats[i, ], label.size = 5,label = "p.adj.signif"))
#   
#   # graph_i <- 
#   # print(graph.i)
# }
# 
# # ggarrange(graph.1)
# 
# ggarrange(graph.1,graph.3,graph.6,ncol = 3, nrow = 3)
# ggarrange(graph.11,graph.7,graph.2,graph.4,graph.5,graph.8,graph.9,graph.10, ncol = 4, nrow = 3)

```


```{r setup, include=FALSE}
#Remove other class variables

df <- df %>%
  select(-FIBR_PREDS:LET_IS)

```

```{r setup, include=FALSE}
#Correlation plot for numeric variables
#Point-Biserial coefficient
library(corrplot)

df_corr_numeric <- df_numeric 
df_corr_numeric$any_complication <- recode(as.character(df_corr_numeric$any_complication), 'FALSE' = 0, 'TRUE' = 1)

testRes <- cor.mtest(df_corr_numeric, conf.level = 0.95)
corrplot(cor(df_corr_numeric, use = 'pairwise.complete.obs'), p.mat = testRes$p, method = "color", diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, 
         insig = 'label_sig', pch.col = 'purple')

# http://web.pdx.edu/~newsomj/pa551/lectur15.htm

```
```{r fig.align="center", echo = FALSE,fig.height = 10, fig.width = 10}
#Correlation plot for binary variables
#Phi Coefficient correlation
library(corrplot)

binary_cols <- c(3, 8, 10, 13:34, 39:44, 49:83, 85, 96:99, 106:112)
df_corr_binary <- df[c(binary_cols, 125)]
df_corr_binary$any_complication <- recode(as.character(df_corr_binary$any_complication), 'FALSE' = 0, 'TRUE' = 1)

#Do not include IBS_NASL (variable 2) since it has 1628/1700 missing values
df_corr_binary_1 <- df_corr_binary[c(1,3:40, 79)]


testRes <- cor.mtest(df_corr_binary_1, conf.level = 0.95)
corrplot(cor(df_corr_binary_1, use = "pairwise.complete.obs"), p.mat = testRes$p, method = "color", diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, 
         insig = 'label_sig', pch.col = 'purple', na.label = "NA", number.cex = 0.5, tl.cex = 0.8)

df_corr_binary_2 <- df_corr_binary[c(41:79)]


testRes <- cor.mtest(df_corr_binary_2, conf.level = 0.95)
corrplot(cor(df_corr_binary_2, use = "pairwise.complete.obs"), p.mat = testRes$p, method = "color", diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, 
         insig = 'label_sig', pch.col = 'purple', na.label = "NA", number.cex = 0.5, tl.cex = 0.8)

# https://stat.ethz.ch/pipermail/r-help/2015-April/428127.html
# http://web.pdx.edu/~newsomj/pa551/lectur15.htm
# http://www.ce.memphis.edu/7012/L17_CategoricalVariableAssociation.pdf
```

```{r fig.align="center", echo = FALSE,fig.height = 10, fig.width = 10}
#Correlation plot for categorical/ordinal variables
#Cramer V
library(corrplot)

ordinal_cols <- c(4, 5, 6, 7, 9, 11, 12, 45:48, 92:95, 100:105)

df_corr_ordinal <- df[c(ordinal_cols, 125)]
df_corr_ordinal$any_complication <- recode(as.character(df_corr_ordinal$any_complication), 'FALSE' = 0, 'TRUE' = 1)

chisqmatrix <- function(x) {
  names = colnames(x);  num = length(names)
  m = matrix(nrow=num,ncol=num,dimnames=list(names,names))
  for (i in 1:(num-1)) {
    for (j in (i+1):num) {
      m[i,j] = chisq.test(x[,i],x[,j],)$p.value
    }
  }
  return (m)
}
mat = chisqmatrix(df_corr_ordinal)

corrplot::corrplot(DescTools::PairApply(df_corr_ordinal, DescTools::CramerV), p.mat = mat, method = 'color', diag = FALSE, type = 'upper',
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, 
         insig = 'label_sig', pch.col = 'purple', na.label = "NA", number.cex = 0.5, tl.cex = 0.8)

# https://stackoverflow.com/questions/32732582/chi-square-p-value-matrix-in-r
```

```{r fig.align="center", echo = FALSE,fig.height = 30, fig.width = 30}
library(Hmisc)

data <- df[1:20] %>% mutate(across(everything(), as.integer))
# #Convert NA to "NA" to visualize missing values 
# df_hist <- df
# df_hist[is.na(df_hist)] <- 'NA'
# hist.data.frame(df_hist)
# # hist(df)
# for (col in 2:ncol(df)) {
#     hist(df[,col])
# }
data_long <- data %>%                          # Apply pivot_longer function
  pivot_longer(colnames(data)) %>% 
  as.data.frame()

ggp1 <- ggplot(data_long, aes(x = value)) +    # Draw each column as histogram
  geom_histogram() +
  facet_wrap(~ name, ncol= 4,scales = "free")
ggp1

# https://statisticsglobe.com/histogram-density-for-each-column-data-frame-r
# df_long <- pivot_longer(df, everything(), names_to = "variable", values_to = "observation")
# 
# # specify that 'Variables' are ordered (i.e. Variable_2 is after Variable_1)
# df_long$variable <- factor(df_long$variable, levels = unique(df_long$variable), ordered = TRUE)
# 
# # plot histograms with ggplot
# ggplot(df_long, aes(x = observation)) +
#   geom_histogram(bins = 15) +
#   facet_wrap(~variable, ncol = 6, strip.position = "right")
```

```{r setup, include=FALSE}
#Train/test split
for(i in 1:ncol(df)) {                                   # Replace NA in all columns
  df[ , i][is.na(df[ , i])] <- median(df[ , i], na.rm = TRUE)
}

index <- sort(sample(nrow(df), nrow(df)*.7))
train <- df[index,]
test <- df[-index,]



medical_history_cols <- c(4:8, 11:12, 13:34)
symptoms_cols <- c(9:10, 35:43, 49, 83:91)
drugs_cols <- c(76:82, 96:112)
missing_values_cols <- c('KFK_BLOOD', 'S_AD_KBRIG', 'D_AD_KBRIG', 'IBS_NASL')
new_train <- train[c(medical_history_cols, symptoms_cols, drugs_cols, 125)] %>%
  select(-all_of(missing_values_cols))

new_test <- test %>% 
  select(all_of(colnames(new_train)))
  
lapply(new_train, function(x) length(which(is.na(x))))
```

```{r setup, include=FALSE}
#Logistic Regression

sig_cols <- c('LID_S_n', 'NITR_S', 'NOT_NA_KB', 'NA_BLOOD', 'O_L_POST', 'zab_leg_02', 'zab_leg_01', 'endocr_01')
train_final <- new_train %>% select(all_of(c(sig_cols, 'any_complication')))
test_final <- new_test %>% select(all_of(c(sig_cols, 'any_complication')))

LR_model <- glm(any_complication ~.,family = binomial(link = 'logit'), data = new_train, na.action = na.omit)
summary(LR_model)
# https://datascienceplus.com/perform-logistic-regression-in-r/#:~:text=Logistic%20regression%20is%20a%20method,general%2C%20can%20assume%20different%

#https://www.datacamp.com/community/tutorials/logistic-regression-R
#https://towardsdatascience.com/machine-learning-with-r-logistic-regression-152ec20351db
result <- predict(LR_model, newdata = new_test, type = 'response')

# optCutOff <- optimalCutoff(test$Churn, result)[1] 
preds<- ifelse(result > 0.5, 1,0 )

## Confusion matrix and statistics
library(caret)
caret::confusionMatrix(factor(preds), factor(new_test$any_complication), mode = "everything", positive = "1")

# https://stackoverflow.com/questions/70905642/error-in-lm-fitx-y-na-nan-inf-in-x-in-r

```

```{r setup, include=FALSE}
#Naive Bayes
library('e1071')
 m <- naiveBayes(as.factor(any_complication) ~ ., data = train_final)
 m$tables
 print(m)


 y_pred <- predict(m, test_final)
#
 table(y_pred, test_final$any_complication)
#
 cm <- table(y_pred, new_test$any_complication)
 cm

```

```{r setup, include=FALSE}
#Random Forest
library(randomForest)

train_RF <- train_final
train_RF$any_complication <- as.character(train_RF$any_complication)
train_RF$any_complication <- as.factor(train_RF$any_complication)

RF_model <- randomForest(any_complication ~., data=train_RF, proximity = TRUE, na.action = na.exclude) 

preds <- predict(RF_model, test_final)

caret::confusionMatrix(factor(preds), factor(test_final$any_complication), mode = "everything", positive = "1")

# https://www.r-bloggers.com/2021/04/random-forest-in-r/
# https://discuss.analyticsvidhya.com/t/what-does-the-warning-the-response-has-five-or-fewer-unique-values-while-building-random-forest-mean/6442/2
```

```{r setup, include=FALSE}
#Neural Network
library(neuralnet)

#Fill in missing values with median to allow NN to train
train_NN <- train_final

for(i in 1:ncol(train_NN)) {                                   # Replace NA in all columns
  train_NN[ , i][is.na(train_NN[ , i])] <- median(train_NN[ , i], na.rm = TRUE)
}

NN_model <- neuralnet(any_complication ~ ., data = train_NN, hidden = c(2,1), linear.output = FALSE, threshold=0.01)


#Test the resulting output
test_NN <- test_final %>% 
  select(-any_complication)

nn.results <- compute(NN_model, test_NN)
results <- data.frame(actual = test_final$any_complication, prediction = nn.results$net.result)

roundedresults<-sapply(results,round,digits=0)
roundedresultsdf=data.frame(roundedresults)
attach(roundedresultsdf)
confusionMatrix(table(actual,prediction), positive = "1")
# https://stackoverflow.com/questions/63770095/how-to-print-confusion-matrix-of-neuralnet-predicted-probabilities
# https://datascienceplus.com/neuralnet-train-and-test-neural-networks-using-r/

library(nnet)

irispred <- nnet(any_complication ~ ., data = train_NN, size=10)
result <- predict(irispred, newdata = test_final)
preds <- ifelse(result > 0.5, 1,0 )

confusionMatrix(data = factor(preds), reference = factor(test_final$any_complication), mode = "everything", positive = "1")

result <- predict(LR_model, newdata = new_test, type = 'response')

# optCutOff <- optimalCutoff(test$Churn, result)[1] 
preds<- ifelse(result > 0.5, 1,0 )


```